{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Day 4 Evaluation and Augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KTvJB4kTsVG",
        "colab_type": "text"
      },
      "source": [
        "# Model Evaluation and Data Augmentation\n",
        "\n",
        "Now that we have trained our model, let's see how good the model is. There are several approaches for evaluating model training and classification performance such as training curves, AUROC, and F1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf5XdzDfoaCN",
        "colab_type": "text"
      },
      "source": [
        "### Setup drive\n",
        "\n",
        "Run the following cell to mount your Drive onto Colab. Go to the given URL and once you login and copy and paste the authorization code, you should see \"drive\" pop up in the files tab on the left."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWNwff0qoeHm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "700a7b3a-3ddc-42a7-a91d-a429cf241668"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ2vK0Wkoh91",
        "colab_type": "text"
      },
      "source": [
        "Click the little triangle next to \"drive\" and navigate to the \"AI4All Chest X-Ray Project\" folder. Hover over the folder and click the 3 dots that appear on the right. Select \"copy path\" and replace `PASTE PATH HERE` with the path to your folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmsbus7EolZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6951318e-cf72-475b-e21f-cd756364eecf"
      },
      "source": [
        "cd \"/content/drive/My Drive/AI4All Chest X-Ray Project\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1iJKbtzLay6C-5OfpVHhbe1nQeNGyhFWO/AI4All Chest X-Ray Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTEH61rgoys8",
        "colab_type": "text"
      },
      "source": [
        "### Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-MFSQW9TsVH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e563413e-2c95-4729-a662-0e9300afe53f"
      },
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from utils.plotting import imshow_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l-MiFYaTsVN",
        "colab_type": "text"
      },
      "source": [
        "### Setup paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41KCntJjTsVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_dataset = os.path.join('data')\n",
        "\n",
        "path_to_images = os.path.join(path_to_dataset, 'images')\n",
        "\n",
        "metadata = pd.read_csv(os.path.join(path_to_dataset, 'metadata_train.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S89n951MrdU",
        "colab_type": "text"
      },
      "source": [
        "### Define helper functions\n",
        "\n",
        "We worked on these functions in the last notebook. They are defined here in case you want to take a look at how they are implemented. I will also provide them in the helper library so that they can be imported for future notebooks (without copying the code over and over).\n",
        "\n",
        "**Define functions for splitting dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD3437bsTsVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_val_sizes(dataset, train_ratio):\n",
        "  '''Calculate train and validation sizes based on dataset size and ratio of \n",
        "  data to keep in training set'''\n",
        "\n",
        "  train_size = int(train_ratio * len(dataset))\n",
        "  val_size = len(dataset) - train_size\n",
        "\n",
        "  return train_size, val_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkT8WjrcTsVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_val_sets(dataset, train_ratio, batch_size):\n",
        "  '''Randomly splits data into training and validation sets based on specified ratio'''\n",
        "\n",
        "  # calculate training and validation set sizes\n",
        "  train_size, val_size = get_train_val_sizes(dataset, train_ratio)\n",
        "\n",
        "  # split dataset into two training set and validation set\n",
        "  train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "  # create dataloaders\n",
        "  train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size)\n",
        "  val_loader = DataLoader(dataset=val_dataset, shuffle=False, batch_size=len(val_dataset))\n",
        "\n",
        "  return train_loader, val_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDB9qNLgqdcN",
        "colab_type": "text"
      },
      "source": [
        "**Define functions for training neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_1aH4RLTsVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(predicted, actual):\n",
        "    '''Given predicted and actual labels, calculate accuracy'''\n",
        "    accuracy = torch.mean((predicted == actual).float())\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wl9g36vTsVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, inputs):\n",
        "    '''Return class label with highest probability as the model prediction'''\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    return predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHXKoJUQTsVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, val_loader, epoch_num=1, lr=0.001):\n",
        "    '''Trains a neural network\n",
        "\n",
        "    Args:\n",
        "        model: torch model\n",
        "        train_loader (DataLoader): training data\n",
        "        val_loader (DataLoader): validation data\n",
        "        epoch_num (int): number of epochs\n",
        "        lr (float): learning rate\n",
        "\n",
        "    Return:\n",
        "        None (plots loss over iterations)\n",
        "    '''\n",
        "    \n",
        "    # define loss and optimization functions\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # load validation set\n",
        "    inputs_val, targets_val = next(iter(val_loader))\n",
        "    \n",
        "    # create variables for tracking loss and accuracy values\n",
        "    train_accuray_log = []\n",
        "    val_accuracy_log = []\n",
        "    loss_log = []\n",
        "\n",
        "    for epoch in range(epoch_num):\n",
        "\n",
        "        for batch_num, data in enumerate(train_loader):\n",
        "\n",
        "            inputs, targets = data\n",
        "\n",
        "            # set parameter gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # calculate loss and update weights\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # calculate accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_accuracy = calc_accuracy(predicted, targets)\n",
        "            \n",
        "            # calculate validation accuracy\n",
        "\n",
        "            predicted = predict(model, inputs_val)\n",
        "            val_accuracy = calc_accuracy(predicted, targets_val)\n",
        "\n",
        "            # record loss and accuracy values\n",
        "            loss_log.append(loss)\n",
        "            train_accuray_log.append(train_accuracy.item())\n",
        "            val_accuracy_log.append(val_accuracy.item())\n",
        "\n",
        "            # print loss\n",
        "            print('[epoch {} batch {}] Loss: {:.3f} Train accuracy: {:.3f} Val accuracy: {:.3f}'\n",
        "                  .format(epoch, batch_num, loss, train_accuracy, val_accuracy))\n",
        "\n",
        "\n",
        "    print('Finished Training')\n",
        "    return train_accuray_log, val_accuracy_log, loss_log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2y19y7cpc35",
        "colab_type": "text"
      },
      "source": [
        "### Train NN model\n",
        "\n",
        "This is the whole pipeline so far! We've gone through preprocessing, splitting the data into training and validation sets, setting up a neural network, and training the model. (Whew!)\n",
        "\n",
        "Play around with modifying parameters and inputs in this section to change your neural network!\n",
        "\n",
        "**Preprocess data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcFB-yFPTsVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_MEAN = 0.544\n",
        "DATA_STD = 0.237\n",
        "\n",
        "# smaller image size for quicker training\n",
        "RESIZE_SIZE = 50\n",
        "CROP_SIZE = 50 \n",
        "\n",
        "IM_SIZE = CROP_SIZE\n",
        "\n",
        "# transformations\n",
        "data_transforms = transforms.Compose([\n",
        "        transforms.Grayscale(),\n",
        "        transforms.Resize(IM_SIZE),\n",
        "        transforms.CenterCrop(IM_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=DATA_MEAN, std=DATA_STD)])\n",
        "\n",
        "dataset = datasets.ImageFolder(path_to_images, transform=data_transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCtBstXnTsVV",
        "colab_type": "text"
      },
      "source": [
        "**Split the data into training and validation set**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8CGpuaVMSNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ratio = 0.75\n",
        "batch_size = 64\n",
        "train_loader, val_loader = get_train_val_sets(dataset, train_ratio, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55YzQuLiTsVh",
        "colab_type": "text"
      },
      "source": [
        "**Setup fully connected network**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmjXS45QTsVi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "cebe6ebf-1ea8-45a0-b51f-790999c099cc"
      },
      "source": [
        "input_size = IM_SIZE * IM_SIZE\n",
        "\n",
        "# define network\n",
        "model = nn.Sequential(nn.Flatten(),\n",
        "                      nn.Linear(input_size, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Flatten()\n",
            "  (1): Linear(in_features=2500, out_features=64, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=64, out_features=16, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): Linear(in_features=16, out_features=2, bias=True)\n",
            "  (6): LogSoftmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2bmWeRbeUNR",
        "colab_type": "text"
      },
      "source": [
        "**Train network**\n",
        "\n",
        "Note: if the model is running too slow, try defining a smaller model for speed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPGqvPzOTsVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_accuray_log, val_accuracy_log, loss_log = train(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTFCBA-9TsVq",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate model performance\n",
        "\n",
        "It's hard to look at the printed output to evaluate the model performance. Let's consider a few evaluation approaches using plots and metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMaPz-3yi-7X",
        "colab_type": "text"
      },
      "source": [
        "### Training curves\n",
        "\n",
        "Plotting the model performance over training iterations (batches / epochs) is helpful for assessing how the model training is going. Loss (error) and accuracy (correctness) are two useful indicators to plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfU9Zp47TsVq",
        "colab_type": "text"
      },
      "source": [
        "**Loss curve**\n",
        "\n",
        "The loss curve tracks the loss (error) over iterations (training).  We used the negative log-likelihood loss (NLLLoss) in the model. In combination with log softmax activation in the final layer, this produces the cross entropy loss. You have already calculated the loss log (`loss_log`) over iterations in the train function - just need to plot it! \n",
        "\n",
        "Note: In addition to the training loss, you can modify the `train` function to record the validation loss and it plot to compare with the training loss.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkZfqLdXiXKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXERCISE: Plot the loss curve over iterations (batches). The plot should show \n",
        "# loss on the y-axis and iterations on the x-axis.\n",
        "# Tip: plt.plot()\n",
        "\n",
        "def plot_loss_curve(loss):\n",
        "\n",
        "  ### WRITE CODE HERE ###\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T_RalyoNceK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_loss_curve(loss_log)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYQIt5bIN4ZL",
        "colab_type": "text"
      },
      "source": [
        "**Questions:** Based on the loss curve, is the model converging? Has it converged? How stable is the training? \n",
        "\n",
        "Try changing the epoch number, batch size, learning rate, or other parameters and check how the loss curve changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5kzyJMUlMjO",
        "colab_type": "text"
      },
      "source": [
        "**Accuracy curves**\n",
        "\n",
        "Similarly, plot the training and validation accuracy curves. Comparing the model performance on training and validation sets allows us to assess whether the model is overfitting or underfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKNcObktTsVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXERCISE: Plot the training and validation accuracy curves on the same plot.\n",
        "\n",
        "def plot_training_curve(train, val):\n",
        "\n",
        "    ### WRITE CODE HERE ###\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajtikw3sTsVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_training_curve(train_accuray_log, val_accuracy_log)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9xjqNtO3VLZ",
        "colab_type": "text"
      },
      "source": [
        "**Question:** Comparing the training and validation curves, is the model overfitting or underfitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7SkimmqTsVt",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation metrics\n",
        "\n",
        "**Confusion matrix**\n",
        "\n",
        "The confusion matrix summarizes the predictions across their actual class labels. [Read more here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1t8_VPWQAtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(confusion_mat):\n",
        "  '''Plots the confusion matrix\n",
        "\n",
        "  Args:\n",
        "    confusion_mat: confusion matrix\n",
        "  '''\n",
        "  cm_df = pd.DataFrame(\n",
        "      cm, \n",
        "      index = [idx for idx in ['COVID-19', 'No Finding']],\n",
        "      columns = [col for col in ['COVID-19 (pred)', 'No Finding (pred)']])\n",
        "  plt.figure(figsize = (8,6))\n",
        "  sns.heatmap(cm_df, annot=True)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PbqlndITsVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXERCISE: Calculate the confusion matrix for the validation set and plot it.\n",
        "# Tip: use the imported confusion_matrix function to calculate the matrix and \n",
        "# the plot_confusion_matrix function above to plot the matrix.\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "### WRITE CODE HERE ###\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFg1IWOBQvRP",
        "colab_type": "text"
      },
      "source": [
        "**Question**: What do each cell of the matrix represent? What are the true positive rate and the false positive rate?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPBwuow3vBsc",
        "colab_type": "text"
      },
      "source": [
        "**AUROC**\n",
        "\n",
        "There are two common ways to combine the information in a confusion matrix into a single metric for evaluating model performance: AUROC and F1 score\n",
        "\n",
        "The ROC plots the true postive rate versus the false positive rate ([read more here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)). AUROC is the area under the curve. An AUROC of 1 indicates good model discrimination between the classes whereas an AUROC of 0.5 indicates poor discrimination. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XCoTBUxsHYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flip_labels(labels):\n",
        "  '''Swaps Covid (0 to 1) and No Finding (1 to 0) labels'''\n",
        "  return 1 - labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22YEutt4u-eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXERCISE?\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# calculate roc curve and auroc\n",
        "outputs = model(inputs_val)\n",
        "log_covid_prob = torch.index_select(outputs, 1, torch.tensor([0])).detach()\n",
        "\n",
        "covid_prob = torch.exp(log_covid_prob)\n",
        "\n",
        "fpr, tpr, _ = roc_curve(flip_labels(targets_val), covid_prob)\n",
        "auroc = auc(fpr, tpr)\n",
        "\n",
        "# plot roc curve\n",
        "plt.plot(fpr, tpr, color='red')\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title(f'ROC Curve: area = {auroc:.3f}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxu8L8PGTsVv",
        "colab_type": "text"
      },
      "source": [
        "**Precision, recall, F1 score**\n",
        "\n",
        "Another way to measure model performance is using precision and recall. These are also calculated using the the values in the confusion matrix. The F1 score combines precision and recall into a single metric. ([Read more here](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py))\n",
        "\n",
        "**Question:** How do precision and recall differ from true positive rate or false positive rate?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUbz987yTsVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXERCISE: Use the important methods to calculate precision, recall, and f1 score\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "targets_val = flip_labels(targets_val)\n",
        "predicted = flip_labels(predicted)\n",
        "\n",
        "precision_score = # CODE HERE #\n",
        "recall_score =  # CODE HERE #\n",
        "f1_score =  # CODE HERE #\n",
        "\n",
        "print(f'Precision: {precision_score:.3f}')\n",
        "print(f'Recall: {recall_score:.3f}')\n",
        "print(f'F1 Score: {f1_score:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNsGELXaTsVx",
        "colab_type": "text"
      },
      "source": [
        "**Error Analysis** \n",
        "\n",
        "Metrics are one way to assess a model. We can often gain more insight by examining the predictions directly. By analyzing when (for which cases) the model predicts incorrectly, we can generate additional hypotheses on how we should train the model for better performance.\n",
        "\n",
        "Some ideas to consider\n",
        "- Duplicated patients in training and validation sets\n",
        "- Metadata information: views, location, sex/age\n",
        "- Severity\n",
        "\n",
        "This a potential follow-up idea if you are interested!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc8y4215vPav",
        "colab_type": "text"
      },
      "source": [
        "### Apply evaluation\n",
        "\n",
        "Apply the evaluation methods above to your model. Play around with tweaking model parameters for better performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRck3hJAv0bM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXERCISE\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwdX2MN0384J",
        "colab_type": "text"
      },
      "source": [
        "### Data Augmentation (Bonus)\n",
        "\n",
        "If the model does not have enough training examples or is not generalizing well (overfitting), data augmentation is one strategy to increase the training data size and to broaden the range of training signal. We can use data transforms to define augmentation the preprocessing step. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFwhNCNf5F06",
        "colab_type": "text"
      },
      "source": [
        "**Agumentation transforms**\n",
        "\n",
        "Apply transforms that could improve the generalizability of the model by adding realistic diversity to the dataset. Consider which transforms to use. Some transforms may actually increase the bias in the data and produce worse performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViaAhYKR3_Fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXERCISE: Define augmentation transforms\n",
        "\n",
        "augmentation_transforms = # CODE HERE #\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSeNclsF4fR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imshow_dataset(dataset, rand=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zziiiZWy5g7c",
        "colab_type": "text"
      },
      "source": [
        "**Add data augmentation transformations to preprocessing**\n",
        "\n",
        "Make sure resize and center crop are appropriately resized so that the region of interest (lung area) is not cropped out and the image still covers the full frame.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl4kXSfW5bSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXERCISE: Modify transforms as needed\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "            transforms.Grayscale(),\n",
        "            transforms.Resize(256),\n",
        "            *augmentation_transforms,\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[DATA_MEAN], std=[DATA_STD])])\n",
        "\n",
        "dataset = datasets.ImageFolder(path_to_images, transform=data_transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ0Lkf9q4bw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imshow_dataset(dataset, rand=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeVnrOng53mH",
        "colab_type": "text"
      },
      "source": [
        "**Retrain network**\n",
        "\n",
        "Apply transforms with augmentation to the pipeline and retrain the network. How does it improve performance?\n",
        "\n",
        "Note: The augmentation transforms should only be added to training set. (Why?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ueRUNt458rT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXERCISE\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}